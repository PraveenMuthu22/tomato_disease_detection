{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda7ceab83e014245f08343a289820ad1a4",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warmup_model_path = 'vgg-warmup-model.h5'\n",
    "model_save_path = 'vgg16-fined-tuned.h5'\n",
    "dataset_name = 'plantVillage-tomato-mohanty'\n",
    "dataset_path = '../datasets/' + dataset_name\n",
    "checkpoint_path = 'finetuning-checkpoints.hdf5'\n",
    "input_width = 224\n",
    "input_height = 224\n",
    "input_depth = 3\n",
    "\n",
    "batch_size = 32\n",
    "num_of_epochs = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.13.1\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    warmup_model_path,\n",
    "    custom_objects=None,\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model(warmup_model_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print index of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[INFO] 0\tInputLayer\n[INFO] 1\tConv2D\n[INFO] 2\tConv2D\n[INFO] 3\tMaxPooling2D\n[INFO] 4\tConv2D\n[INFO] 5\tConv2D\n[INFO] 6\tMaxPooling2D\n[INFO] 7\tConv2D\n[INFO] 8\tConv2D\n[INFO] 9\tConv2D\n[INFO] 10\tMaxPooling2D\n[INFO] 11\tConv2D\n[INFO] 12\tConv2D\n[INFO] 13\tConv2D\n[INFO] 14\tMaxPooling2D\n[INFO] 15\tConv2D\n[INFO] 16\tConv2D\n[INFO] 17\tConv2D\n[INFO] 18\tMaxPooling2D\n[INFO] 19\tFlatten\n[INFO] 20\tDense\n[INFO] 21\tDropout\n[INFO] 22\tDense\n"
    }
   ],
   "source": [
    "# iterate for all layers in the network and print its' index value\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(\"[INFO] {}\\t{}\".format(i,layer.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreeze final CONV layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x657dbfc18>\n<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x657dbfd68>\n<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x6585b83c8>\n<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x657dbfe80>\n<tensorflow.python.keras.layers.core.Flatten object at 0x657dbff28>\n<tensorflow.python.keras.layers.core.Dense object at 0x657dbff98>\n<tensorflow.python.keras.layers.core.Dropout object at 0x6555570f0>\n<tensorflow.python.keras.layers.core.Dense object at 0x655557128>\n"
    }
   ],
   "source": [
    "for layer in model.layers[15:]:\n",
    "  print(layer)\n",
    "  # layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# Build the model from the new\n",
    "print(\"[INFO] re-compiling model ...\")\n",
    "opt = SGD(lr=0.001)\n",
    "# Fine-tuning with a small learning rate\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image   import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras .applications import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.preprocessors.aspect_aware_preprocessor import AspectAwarePreprocessor\n",
    "from utils.preprocessors.image_to_array_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.io.simple_dataset_loader import SimpleDatasetLoader\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(   rotation_range=30,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "# Load image paths\n",
    "print(\"[INFO] loading images...\")\n",
    "image_paths = list(paths.list_images(dataset_path))\n",
    "\n",
    "# Initial image preprocessing\n",
    "aap = AspectAwarePreprocessor(input_width, input_height)\n",
    "iap= ImageToArrayPreprocessor()\n",
    "\n",
    "#Load image data and perform image data preprocessing\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap,iap])\n",
    "(data,labels)  = sdl.load(image_paths,verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "\n",
    "\n",
    "# train test split\n",
    "(train_x,test_x,train_y,test_y) = train_test_split(data,labels,test_size=0.25,random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "train_y = LabelBinarizer().fit_transform(train_y)\n",
    "test_y = LabelBinarizer().fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', \n",
    "save_best_only=True, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "#load checkpoints if existing\n",
    "import os\n",
    "\n",
    "epochs_done = 1\n",
    "\n",
    "if(os.path.exists(checkpoint_path)):\n",
    "    model.load_weights(checkpoint_path)\n",
    "    num_of_epochs = num_of_epochs - epochs_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    aug.flow(train_x,train_y, batch_size = 32),\n",
    "             validation_data = (test_x,test_y),\n",
    "             epochs=num_of_epochs,\n",
    "             steps_per_epoch = len(train_x) //32,\n",
    "             verbose = 1,\n",
    "             callbacks=callbacks)\n",
    "\n",
    "model.save(model_save_path)"
   ]
  }
 ]
}