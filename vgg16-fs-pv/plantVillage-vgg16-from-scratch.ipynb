{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classes:  ['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']\n3\n"
    }
   ],
   "source": [
    "num_of_epochs = 5\n",
    "batch_size = 32\n",
    "dataset_name = 'plantVillage-test-mohanty'\n",
    "dataset_path = '../datasets/' + dataset_name\n",
    "model_diagram_path = 'vgg16-top-removed.png'\n",
    "model_save_path = 'plantVillage-alexnet-from-scratch.h5'\n",
    "plot_save_path = 'plot-plantVillage-alexnet-from-scratch.png'\n",
    "\n",
    "input_width = 224\n",
    "input_height = 224\n",
    "input_depth = 3\n",
    "\n",
    "\n",
    "# Get classes\n",
    "import os\n",
    "import re\n",
    "classes = os.listdir(dataset_path)\n",
    "class_names = []\n",
    "\n",
    "for i in classes:\n",
    "    if(re.search(\"Tomato___\", i)):\n",
    "        class_names.append(i)\n",
    "    \n",
    "print('Classes: ', class_names)\n",
    "print(len(class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape = (input_width, input_height, input_depth)))\n",
    "\n",
    "base_model.summary()\n",
    "plot_model(base_model, to_file=model_diagram_path, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach new head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# Create head part\n",
    "head_model = base_model.output\n",
    "\n",
    "head_model = Flatten(name='flatten')(head_model)\n",
    "head_model = Dense(4096,activation='relu')(head_model)\n",
    "head_model = Dense(4096,activation='relu')(head_model)\n",
    "head_model = Dense(len(class_names),activation='softmax')(head_model)\n",
    "\n",
    "# Attach head to model\n",
    "model = Model(inputs=base_model.input, outputs = head_model)\n",
    "\n",
    "model_diagram_path = 'vgg16-output-modified.png'\n",
    "plot_model(model, to_file=model_diagram_path, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copile model\n",
    "opt = SGD(lr=0.05)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1458 images loaded\n['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']\n[INFO]: Processed 500/1458\n[INFO]: Processed 1000/1458\n"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "\n",
    "from utils.preprocessors.aspect_aware_preprocessor import AspectAwarePreprocessor\n",
    "from utils.preprocessors.image_to_array_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.io.simple_dataset_loader import SimpleDatasetLoader\n",
    "\n",
    "# Get the list of image names\n",
    "image_paths = list(paths.list_images(dataset_path))\n",
    "\n",
    "print(len(image_paths), 'images loaded')\n",
    "\n",
    "# Get unique class_names\n",
    "class_names = [pt.split(os.path.sep)[-2] for pt in image_paths]\n",
    "class_names = [str(x) for x in np.unique(class_names)]\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "# Preprocessors\n",
    "aap = AspectAwarePreprocessor(input_width, input_height)\n",
    "itap = ImageToArrayPreprocessor()\n",
    "\n",
    "# Add preprocessors to DataSetLoader class\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, itap])\n",
    "\n",
    "(data, labels) = sdl.load(image_paths, verbose=500)\n",
    "data = data.astype('float') / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode labels and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training (75%) and testing (25%) data\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels,\n",
    "test_size=0.25, random_state=0)\n",
    "\n",
    "# Convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[INFO] training network...\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 1093 samples, validate on 365 samples\nEpoch 1/5\n  64/1093 [>.............................] - ETA: 22:50 - loss: 4.4007 - acc: 0.3438"
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(train_x, train_y, validation_data=(test_x, test_y),\n",
    "              batch_size=batch_size, epochs=num_of_epochs, verbose=1)\n",
    "\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate classfication report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# If one hot encoding is used\n",
    "predictions = model.predict(test_x, batch_size=batch_size)\n",
    "print(classification_report(test_y.argmax(axis=1), predictions.argmax(axis=1), target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(plot_save_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}