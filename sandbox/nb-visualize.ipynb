{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classes:  ['Tomato___Target_Spot', 'Tomato___Late_blight', 'Tomato___Tomato_mosaic_virus', 'Tomato___Leaf_Mold', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Two-spotted_spider_mite', 'Tomato___healthy', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Septoria_leaf_spot']\n10\n"
    }
   ],
   "source": [
    "num_of_epochs = 25\n",
    "batch_size = 32\n",
    "dataset_name = 'tomato-dataset'\n",
    "dataset_path = '../datasets/' + dataset_name\n",
    "model_save_path = 'model.h5'\n",
    "\n",
    "checkpoint_path = 'checkpoints.hdf5'\n",
    "\n",
    "input_width = 224\n",
    "input_height = 224\n",
    "input_depth = 3\n",
    "\n",
    "# Get classes\n",
    "import os\n",
    "import re\n",
    "classes = os.listdir(dataset_path)\n",
    "class_names = []\n",
    "\n",
    "for i in classes:\n",
    "    if(re.search(\"Tomato___\", i)):\n",
    "        class_names.append(i)\n",
    "    \n",
    "print('Classes: ', class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Input\n",
    "from utils.models.alexnet import alexnet\n",
    "\n",
    "\n",
    "\n",
    "# Load pretrianed VGG model with FC layers removed\n",
    "# explicitly deﬁne the input_tensor to be 224×224×3 pixels\n",
    "# base_model = VGG16( weights=None,\n",
    "#                     include_top=False,\n",
    "#                     input_tensor=Input(shape = (input_width,input_height, input_depth)))\n",
    "\n",
    "\n",
    "model = alexnet(1000)\n",
    "plot_save_path = 'diagram.png'\n",
    "plot_model(model, to_file=plot_save_path, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "][0]             \n__________________________________________________________________________________________________\nconv2d_169 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_16[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_169[0][0]                 \n__________________________________________________________________________________________________\nactivation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n__________________________________________________________________________________________________\nactivation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n__________________________________________________________________________________________________\nactivation_172 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n__________________________________________________________________________________________________\nactivation_173 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_164[0][0]             \n                                                                 activation_167[0][0]             \n                                                                 activation_172[0][0]             \n                                                                 activation_173[0][0]             \n__________________________________________________________________________________________________\nconv2d_172 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_172[0][0]                 \n__________________________________________________________________________________________________\nactivation_176 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n__________________________________________________________________________________________________\nconv2d_173 (Conv2D)             (None, 12, 12, 192)  258048      activation_176[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_173[0][0]                 \n__________________________________________________________________________________________________\nactivation_177 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n__________________________________________________________________________________________________\nconv2d_170 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_174 (Conv2D)             (None, 12, 12, 192)  258048      activation_177[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_165 (BatchN (None, 12, 12, 192)  576         conv2d_170[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_169 (BatchN (None, 12, 12, 192)  576         conv2d_174[0][0]                 \n__________________________________________________________________________________________________\nactivation_174 (Activation)     (None, 12, 12, 192)  0           batch_normalization_165[0][0]    \n__________________________________________________________________________________________________\nactivation_178 (Activation)     (None, 12, 12, 192)  0           batch_normalization_169[0][0]    \n__________________________________________________________________________________________________\nconv2d_171 (Conv2D)             (None, 5, 5, 320)    552960      activation_174[0][0]             \n__________________________________________________________________________________________________\nconv2d_175 (Conv2D)             (None, 5, 5, 192)    331776      activation_178[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_166 (BatchN (None, 5, 5, 320)    960         conv2d_171[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_170 (BatchN (None, 5, 5, 192)    576         conv2d_175[0][0]                 \n__________________________________________________________________________________________________\nactivation_175 (Activation)     (None, 5, 5, 320)    0           batch_normalization_166[0][0]    \n__________________________________________________________________________________________________\nactivation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_170[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_11 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_175[0][0]             \n                                                                 activation_179[0][0]             \n                                                                 max_pooling2d_11[0][0]           \n__________________________________________________________________________________________________\nconv2d_180 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_175 (BatchN (None, 5, 5, 448)    1344        conv2d_180[0][0]                 \n__________________________________________________________________________________________________\nactivation_184 (Activation)     (None, 5, 5, 448)    0           batch_normalization_175[0][0]    \n__________________________________________________________________________________________________\nconv2d_177 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_181 (Conv2D)             (None, 5, 5, 384)    1548288     activation_184[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n__________________________________________________________________________________________________\nactivation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n__________________________________________________________________________________________________\nactivation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n__________________________________________________________________________________________________\nconv2d_178 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n__________________________________________________________________________________________________\nconv2d_179 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n__________________________________________________________________________________________________\nconv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n__________________________________________________________________________________________________\nconv2d_183 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n__________________________________________________________________________________________________\naverage_pooling2d_17 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_176 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_178[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_174 (BatchN (None, 5, 5, 384)    1152        conv2d_179[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_178 (BatchN (None, 5, 5, 384)    1152        conv2d_183[0][0]                 \n__________________________________________________________________________________________________\nconv2d_184 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_17[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_171 (BatchN (None, 5, 5, 320)    960         conv2d_176[0][0]                 \n__________________________________________________________________________________________________\nactivation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n__________________________________________________________________________________________________\nactivation_183 (Activation)     (None, 5, 5, 384)    0           batch_normalization_174[0][0]    \n__________________________________________________________________________________________________\nactivation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n__________________________________________________________________________________________________\nactivation_187 (Activation)     (None, 5, 5, 384)    0           batch_normalization_178[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_184[0][0]                 \n__________________________________________________________________________________________________\nactivation_180 (Activation)     (None, 5, 5, 320)    0           batch_normalization_171[0][0]    \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_182[0][0]             \n                                                                 activation_183[0][0]             \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_186[0][0]             \n                                                                 activation_187[0][0]             \n__________________________________________________________________________________________________\nactivation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_180[0][0]             \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate_3[0][0]              \n                                                                 activation_188[0][0]             \n__________________________________________________________________________________________________\nconv2d_189 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_184 (BatchN (None, 5, 5, 448)    1344        conv2d_189[0][0]                 \n__________________________________________________________________________________________________\nactivation_193 (Activation)     (None, 5, 5, 448)    0           batch_normalization_184[0][0]    \n__________________________________________________________________________________________________\nconv2d_186 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_190 (Conv2D)             (None, 5, 5, 384)    1548288     activation_193[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_190[0][0]                 \n__________________________________________________________________________________________________\nactivation_190 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n__________________________________________________________________________________________________\nactivation_194 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n__________________________________________________________________________________________________\nconv2d_187 (Conv2D)             (None, 5, 5, 384)    442368      activation_190[0][0]             \n__________________________________________________________________________________________________\nconv2d_188 (Conv2D)             (None, 5, 5, 384)    442368      activation_190[0][0]             \n__________________________________________________________________________________________________\nconv2d_191 (Conv2D)             (None, 5, 5, 384)    442368      activation_194[0][0]             \n__________________________________________________________________________________________________\nconv2d_192 (Conv2D)             (None, 5, 5, 384)    442368      activation_194[0][0]             \n__________________________________________________________________________________________________\naverage_pooling2d_18 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_185 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_187[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_183 (BatchN (None, 5, 5, 384)    1152        conv2d_188[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_191[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_187 (BatchN (None, 5, 5, 384)    1152        conv2d_192[0][0]                 \n__________________________________________________________________________________________________\nconv2d_193 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_18[0][0]       \n__________________________________________________________________________________________________\nbatch_normalization_180 (BatchN (None, 5, 5, 320)    960         conv2d_185[0][0]                 \n__________________________________________________________________________________________________\nactivation_191 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n__________________________________________________________________________________________________\nactivation_192 (Activation)     (None, 5, 5, 384)    0           batch_normalization_183[0][0]    \n__________________________________________________________________________________________________\nactivation_195 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n__________________________________________________________________________________________________\nactivation_196 (Activation)     (None, 5, 5, 384)    0           batch_normalization_187[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_193[0][0]                 \n__________________________________________________________________________________________________\nactivation_189 (Activation)     (None, 5, 5, 320)    0           batch_normalization_180[0][0]    \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_191[0][0]             \n                                                                 activation_192[0][0]             \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_195[0][0]             \n                                                                 activation_196[0][0]             \n__________________________________________________________________________________________________\nactivation_197 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_189[0][0]             \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_4[0][0]              \n                                                                 activation_197[0][0]             \n==================================================================================================\nTotal params: 21,802,784\nTrainable params: 21,768,352\nNon-trainable params: 34,432\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "model = InceptionV3( weights=None,\n",
    "                    include_top=False,\n",
    "                    input_tensor=Input(shape = (input_width,input_height, input_depth)))\n",
    "\n",
    "\n",
    "plot_save_path = 'diagram.png'\n",
    "plot_model(model, to_file=plot_save_path, show_shapes=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}