{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda7ceab83e014245f08343a289820ad1a4",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 100\n",
    "batch_size = 32\n",
    "dataset_name = 'plantVillage-tomato-mohanty'\n",
    "dataset_path = '../datasets/' + dataset_name\n",
    "model_save_path = 'vgg-model.h5'\n",
    "\n",
    "\n",
    "model_diagram_path = 'vgg_model_diagram.png'\n",
    "plot_save_path = 'plot-plantVillage-alexnet-from-scratch.png'\n",
    "\n",
    "input_width = 224\n",
    "input_height = 224\n",
    "input_depth = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# Load pretrianed VGG model with FC layers removed\n",
    "# explicitly deﬁne the input_tensor to be 224×224×3 pixels\n",
    "baseModel = VGG16(weights='imagenet',include_top=False,\n",
    "                  input_tensor=Input(shape = (input_width,input_height, input_depth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "class FCHeadNet:\n",
    "    @staticmethod\n",
    "    def build(baseModel,classes,D):\n",
    "        # Initialize the headModel and build this simple architecture\n",
    "        # INPUT => FC => RELU => DO => FC => SOFTMAX\n",
    "        \n",
    "        headModel = baseModel.output\n",
    "        headModel = Flatten(name='flatten')(headModel)\n",
    "        headModel = Dense(D,activation='relu')(headModel)\n",
    "        headModel = Dropout(0.5)(headModel)\n",
    "        # Add a softmaxc layer\n",
    "        headModel = Dense(classes,activation='softmax')(headModel)\n",
    "        return headModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset for trainining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator # \n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras .applications import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args['dataset']))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "\n",
    "# Initial image preprocessing\n",
    "aap = AspectAwarePreprocesser(224,224)\n",
    "iap= ImageToArrayPreprocess()\n",
    "\n",
    "#Load image data and perform image data preprocessing\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap,iap])\n",
    "(data,labels)  = sdl.load(imagePaths,verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX,testX,trainY,testY) = train_test_split(data,labels,\n",
    "\ttest_size=0.25,random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach custom head to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new fully connected layer\n",
    "headModel = FCHeadNet.build(baseModel,len(classNames),256)\n",
    "\n",
    "# place the head FC model on top of the base model \n",
    "model = Model(inputs=baseModel.input,outputs = headModel)\n",
    "\n",
    "# traverse all layers and freeze the weight of the corresponding layer\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm up head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# Since we only train the new fully connected layer, we do a few iterations\n",
    "print(\"[INFO] training head...\")\n",
    "model.fit_generator(aug.flow(trainX,trainY,batch_size = 32),\n",
    "                             validation_data = (testX,testY),epochs=25,\n",
    "                             steps_per_epoch = len(trainX) //32,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate after warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX,batch_size=32)\n",
    "print(classification_report(testY.argmax(axis =1),\n",
    "                            predictions.argmax(axis =1),target_names=classNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreeze some conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers[15:]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we trainfor 100 epochs\n",
    "\n",
    "# Build the model from the new\n",
    "print(\"[INFO] re-compiling model ...\")\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.001)\n",
    "# Fine-tuning with a small learning rate\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = opt,\n",
    "              metrics=['accuracy'])\n",
    "# fine-tuning the entire model\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit_generator(aug.flow(trainX,trainY,batch_size=32),\n",
    "                    validation_data = (testX,testY),epochs = 100,\n",
    "                    steps_per_epoch = len(trainX) // 32,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of fine-tuned model results\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX,batch_size=32)\n",
    "print(classification_report(testY.argmax(axis =1),\n",
    "        predictions.argmax(axis =1),target_names=classNames))\n",
    "\n",
    "# Save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(args['model'])"
   ]
  }
 ]
}