{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 5\n",
    "batch_size = 32\n",
    "dataset_name = 'plantVillage-test-mohanty'\n",
    "dataset_path = '../datasets/' + dataset_name\n",
    "model_diagram_path = 'alexnet_model_diagram.png'\n",
    "model_save_path = 'alexnet_' + dataset_name +'.h5'\n",
    "plot_save_path = 'plot.png'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n1458 images loaded\n['Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy']\n[INFO]: Processed 500/1458\n[INFO]: Processed 1000/1458\n"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "\n",
    "from utils.preprocessors.aspect_aware_preprocessor import AspectAwarePreprocessor\n",
    "from utils.preprocessors.image_to_array_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.io.simple_dataset_loader import SimpleDatasetLoader\n",
    "\n",
    "# Get the list of image names\n",
    "image_paths = list(paths.list_images(dataset_path))\n",
    "\n",
    "print(len(image_paths), 'images loaded')\n",
    "\n",
    "# Get unique class_names\n",
    "class_names = [pt.split(os.path.sep)[-2] for pt in image_paths]\n",
    "class_names = [str(x) for x in np.unique(class_names)]\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "# Preprocessors\n",
    "aap = AspectAwarePreprocessor(227, 227)\n",
    "itap = ImageToArrayPreprocessor()\n",
    "\n",
    "# Add preprocessors to DataSetLoader class\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, itap])\n",
    "\n",
    "(data, labels) = sdl.load(image_paths, verbose=500)\n",
    "data = data.astype('float') / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode labels and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training (75%) and testing (25%) data\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels,\n",
    "test_size=0.25, random_state=0)\n",
    "\n",
    "# Convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 55, 55, 96)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n_________________________________________________________________\nactivation_2 (Activation)    (None, 17, 17, 256)       0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n_________________________________________________________________\nactivation_3 (Activation)    (None, 6, 6, 384)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n_________________________________________________________________\nactivation_4 (Activation)    (None, 4, 4, 384)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 2, 2, 256)         0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4096)              1052672   \n_________________________________________________________________\nactivation_6 (Activation)    (None, 4096)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\nactivation_7 (Activation)    (None, 4096)              0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1000)              4097000   \n_________________________________________________________________\nactivation_8 (Activation)    (None, 1000)              0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1000)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 3)                 3003      \n_________________________________________________________________\nactivation_9 (Activation)    (None, 3)                 0         \n=================================================================\nTotal params: 28,040,483\nTrainable params: 28,040,483\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "import os, sys\n",
    "# import pydot_ng as pydot\n",
    "# pydot.find_graphviz()\n",
    "# os.environ.get('PATH', '')\n",
    "\n",
    "# remove these\n",
    "# sys.path.append('..')\n",
    "# class_names = ['one', 'two', 'three', 'four']\n",
    "# remove these\n",
    "\n",
    "from utils.models.alexnet import alexnet\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = alexnet(len(class_names))\n",
    "model.summary()\n",
    "\n",
    "# plot_model(model, to_file=model_diagram_path, show_shapes=True)\n",
    "\n",
    "# copile model\n",
    "opt = SGD(lr=0.05)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[INFO] training network...\nWARNING:tensorflow:From /Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 1093 samples, validate on 365 samples\nEpoch 1/5\n1093/1093 [==============================] - 113s 103ms/step - loss: 1.0642 - acc: 0.4886 - val_loss: 1.0496 - val_acc: 0.4767\nEpoch 2/5\n1093/1093 [==============================] - 103s 94ms/step - loss: 1.0407 - acc: 0.4904 - val_loss: 1.0361 - val_acc: 0.4767\nEpoch 3/5\n1093/1093 [==============================] - 99s 91ms/step - loss: 1.0151 - acc: 0.5215 - val_loss: 1.3148 - val_acc: 0.2959\nEpoch 4/5\n1093/1093 [==============================] - 99s 91ms/step - loss: 1.0562 - acc: 0.4858 - val_loss: 1.0368 - val_acc: 0.4767\nEpoch 5/5\n1093/1093 [==============================] - 99s 91ms/step - loss: 1.0155 - acc: 0.5050 - val_loss: 1.6798 - val_acc: 0.2959\n"
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(train_x, train_y, validation_data=(test_x, test_y),\n",
    "              batch_size=batch_size, epochs=num_of_epochs, verbose=1)\n",
    "\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate classfication report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\nTomato___Bacterial_spot       0.00      0.00      0.00       174\n  Tomato___Early_blight       0.00      0.00      0.00        83\n       Tomato___healthy       0.30      1.00      0.46       108\n\n               accuracy                           0.30       365\n              macro avg       0.10      0.33      0.15       365\n           weighted avg       0.09      0.30      0.14       365\n\n/Users/praveenmuthukumarana/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# If one hot encoding is used\n",
    "predictions = model.predict(test_x, batch_size=batch_size)\n",
    "print(classification_report(test_y.argmax(axis=1), predictions.argmax(axis=1), target_names=class_names))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\nloss\n[1.0641913340927152, 1.0406997189648306, 1.01506256490046, 1.0562494123952715, 1.0154840067669764]\n\nacc\n[0.48856358647291964, 0.4903934127348667, 0.5215004574701749, 0.48581884723678165, 0.505032022012447]\n\nval_loss\n[1.0495979145781635, 1.036134089182501, 1.3147825139842622, 1.0367660956839992, 1.6798063085503774]\n\nval_acc\n[0.47671232917537426, 0.47671232917537426, 0.2958904110405543, 0.47671232917537426, 0.2958904110405543]\n\n"
    }
   ],
   "source": [
    "print(H.history.keys())\n",
    "\n",
    "print('loss')\n",
    "print(H.history['loss'])\n",
    "print('')\n",
    "\n",
    "print('acc')\n",
    "print(H.history['acc'])\n",
    "print('')\n",
    "\n",
    "\n",
    "print('val_loss')\n",
    "print(H.history['val_loss'])\n",
    "print('')\n",
    "\n",
    "print('val_acc')\n",
    "print(H.history['val_acc'])\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, num_of_epochs), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(plot_save_path)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}