{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inceptionv3-ft-pv-self-eb,ap,lm,ct\n",
    "batch_size = 32\n",
    "dataset_path_plantvillage = '../datasets/plantvillage'\n",
    "dataset_path_self = '../datasets/self'\n",
    "dataset_path_validation = '../datasets/validation'\n",
    "\n",
    "dataset_paths = [dataset_path_plantvillage, dataset_path_self, dataset_path_validation]\n",
    "\n",
    "warmup_model_path = 'model-warmup.h5'\n",
    "model_save_path = 'model-final.h5'\n",
    "checkpoint_path = 'checkpoints-finetuning.hdf5'\n",
    "\n",
    "input_width = 299\n",
    "input_height = 299\n",
    "input_depth = 3\n",
    "\n",
    "# --------------------------------------------------\n",
    "num_of_epochs = 100\n",
    "start_epoch = 0\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select training classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_paths_training = ['../datasets/self/___Early_blight', '../datasets/self/___Appids', '../datasets/self/___Leaf_miner', '../datasets/self/___Curly_top_virus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO]: Processed 500/4849\n",
      "[INFO]: Processed 1000/4849\n",
      "[INFO]: Processed 1500/4849\n",
      "[INFO]: Processed 2000/4849\n",
      "[INFO]: Processed 2500/4849\n",
      "[INFO]: Processed 3000/4849\n",
      "[INFO]: Processed 3500/4849\n",
      "[INFO]: Processed 4000/4849\n",
      "[INFO]: Processed 4500/4849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image   import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras .applications import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.preprocessors.resize_image_preprocessor import resizeImagePreprocessor\n",
    "from utils.preprocessors.image_to_array_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.io.simple_dataset_loader import SimpleDatasetLoader\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(   rotation_range=30,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "def load_datasets(path_list):\n",
    "    # Load image paths\n",
    "    image_paths = []\n",
    "    print(\"[INFO] loading images...\")\n",
    "    for path in path_list:\n",
    "        image_paths.extend(list(paths.list_images(path)))\n",
    "        \n",
    "    # Get unique classnames\n",
    "\n",
    "    class_names = [pt.split(os.path.sep)[-2] for pt in image_paths]\n",
    "    class_names = [str(x) for x in np.unique(class_names)]\n",
    "\n",
    "    # Initial image preprocessing\n",
    "    aap = resizeImagePreprocessor(input_width, input_height)\n",
    "    iap= ImageToArrayPreprocessor()\n",
    "\n",
    "    #Load image data and perform image data preprocessing\n",
    "    sdl = SimpleDatasetLoader(preprocessors=[aap,iap])\n",
    "    (data,labels)  = sdl.load(image_paths,verbose=500)\n",
    "    data = data.astype(\"float\") / 255.0\n",
    "\n",
    "\n",
    "    # train test split\n",
    "    (train_x,test_x,train_y,test_y) = train_test_split(data,labels,test_size=0.25,random_state=42)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    train_y = LabelBinarizer().fit_transform(train_y)\n",
    "    test_y = LabelBinarizer().fit_transform(test_y)\n",
    "    \n",
    "    return (train_x,test_x,train_y,test_y, class_names)\n",
    "\n",
    "(train_x,test_x,train_y,test_y, class_names) = load_datasets(class_paths_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "\n",
    "# model = tf.keras.models.load_model(\n",
    "#     warmup_model_path,\n",
    "#     custom_objects=None,\n",
    "#     compile=False\n",
    "# )\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(warmup_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print index of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate for all layers in the network and print its' index value\n",
    "# for (i,layer) in enumerate(model.layers):\n",
    "#     print(\"[INFO] {:5}\\t{:30}{}\".format(i, layer.name, layer.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreeze final CONV layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfrozen\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "print('unfrozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] re-compiling model ...\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# Build the model from the new\n",
    "print(\"[INFO] re-compiling model ...\")\n",
    "opt = SGD(lr=0.001, momentum=0.09)\n",
    "# Fine-tuning with a small learning rate\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', \n",
    "save_best_only=True, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load checkpoints if existing\n",
    "\n",
    "import os\n",
    "\n",
    "if(os.path.exists(checkpoint_path)):\n",
    "    model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.callbacks.training_monitor import TrainingMonitor\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "fig_path = \"plot\"\n",
    "json_path = \"values.json\"\n",
    "values_path = 'values.json'\n",
    "\n",
    "callbacks.append(TrainingMonitor(fig_path, json_path, start_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 109s 966ms/step - loss: 0.4103 - accuracy: 0.8921 - val_loss: 0.6711 - val_accuracy: 0.7791\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67112, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 95s 842ms/step - loss: 0.3547 - accuracy: 0.9062 - val_loss: 0.6094 - val_accuracy: 0.7923\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67112 to 0.60936, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 94s 832ms/step - loss: 0.3136 - accuracy: 0.9115 - val_loss: 0.5669 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60936 to 0.56695, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 93s 827ms/step - loss: 0.2748 - accuracy: 0.9231 - val_loss: 0.5535 - val_accuracy: 0.8112\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56695 to 0.55350, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 92s 818ms/step - loss: 0.2496 - accuracy: 0.9317 - val_loss: 0.5265 - val_accuracy: 0.8153\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55350 to 0.52651, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 92s 815ms/step - loss: 0.2347 - accuracy: 0.9331 - val_loss: 0.4909 - val_accuracy: 0.8285\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52651 to 0.49085, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 91s 809ms/step - loss: 0.2204 - accuracy: 0.9373 - val_loss: 0.4742 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49085 to 0.47422, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 91s 806ms/step - loss: 0.1994 - accuracy: 0.9467 - val_loss: 0.4673 - val_accuracy: 0.8343\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47422 to 0.46729, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 93s 822ms/step - loss: 0.1936 - accuracy: 0.9440 - val_loss: 0.4514 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46729 to 0.45139, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 91s 806ms/step - loss: 0.1689 - accuracy: 0.9520 - val_loss: 0.4348 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45139 to 0.43475, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 91s 802ms/step - loss: 0.1796 - accuracy: 0.9445 - val_loss: 0.4196 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.43475 to 0.41958, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 90s 798ms/step - loss: 0.1587 - accuracy: 0.9545 - val_loss: 0.4222 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41958\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 90s 799ms/step - loss: 0.1525 - accuracy: 0.9564 - val_loss: 0.4145 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41958 to 0.41449, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 90s 792ms/step - loss: 0.1494 - accuracy: 0.9549 - val_loss: 0.4076 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41449 to 0.40760, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 89s 791ms/step - loss: 0.1458 - accuracy: 0.9538 - val_loss: 0.3952 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40760 to 0.39525, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 89s 784ms/step - loss: 0.1357 - accuracy: 0.9584 - val_loss: 0.3949 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39525 to 0.39493, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 89s 790ms/step - loss: 0.1263 - accuracy: 0.9623 - val_loss: 0.3929 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.39493 to 0.39295, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 89s 783ms/step - loss: 0.1208 - accuracy: 0.9668 - val_loss: 0.3726 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.39295 to 0.37258, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 88s 779ms/step - loss: 0.1133 - accuracy: 0.9677 - val_loss: 0.3743 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.37258\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 88s 776ms/step - loss: 0.1261 - accuracy: 0.9634 - val_loss: 0.3634 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.37258 to 0.36343, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 87s 773ms/step - loss: 0.1088 - accuracy: 0.9673 - val_loss: 0.3703 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.36343\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 87s 767ms/step - loss: 0.1205 - accuracy: 0.9628 - val_loss: 0.3689 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.36343\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 87s 768ms/step - loss: 0.1118 - accuracy: 0.9656 - val_loss: 0.3576 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.36343 to 0.35760, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 86s 765ms/step - loss: 0.1009 - accuracy: 0.9726 - val_loss: 0.3563 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.35760 to 0.35628, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 86s 765ms/step - loss: 0.1117 - accuracy: 0.9649 - val_loss: 0.3471 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35628 to 0.34714, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 86s 765ms/step - loss: 0.0960 - accuracy: 0.9714 - val_loss: 0.3422 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.34714 to 0.34219, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 86s 759ms/step - loss: 0.0899 - accuracy: 0.9731 - val_loss: 0.3462 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34219\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 86s 760ms/step - loss: 0.1015 - accuracy: 0.9684 - val_loss: 0.3393 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.34219 to 0.33927, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 86s 759ms/step - loss: 0.0936 - accuracy: 0.9717 - val_loss: 0.3381 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.33927 to 0.33815, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 86s 761ms/step - loss: 0.0807 - accuracy: 0.9781 - val_loss: 0.3360 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.33815 to 0.33601, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 85s 755ms/step - loss: 0.0900 - accuracy: 0.9686 - val_loss: 0.3301 - val_accuracy: 0.8821\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.33601 to 0.33009, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 87s 770ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.3365 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33009\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 86s 763ms/step - loss: 0.0821 - accuracy: 0.9759 - val_loss: 0.3268 - val_accuracy: 0.8821\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.33009 to 0.32676, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 86s 765ms/step - loss: 0.0848 - accuracy: 0.9748 - val_loss: 0.3241 - val_accuracy: 0.8813\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.32676 to 0.32410, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 85s 754ms/step - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.3195 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32410 to 0.31952, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 86s 757ms/step - loss: 0.0786 - accuracy: 0.9749 - val_loss: 0.3132 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.31952 to 0.31318, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 86s 758ms/step - loss: 0.0791 - accuracy: 0.9756 - val_loss: 0.3202 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31318\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 86s 765ms/step - loss: 0.0767 - accuracy: 0.9754 - val_loss: 0.3143 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31318\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 86s 758ms/step - loss: 0.0691 - accuracy: 0.9786 - val_loss: 0.3080 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.31318 to 0.30802, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 87s 767ms/step - loss: 0.0704 - accuracy: 0.9794 - val_loss: 0.3106 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.30802\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 87s 774ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.3024 - val_accuracy: 0.8920\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.30802 to 0.30240, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 85s 753ms/step - loss: 0.0736 - accuracy: 0.9772 - val_loss: 0.3018 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.30240 to 0.30180, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 88s 781ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.3028 - val_accuracy: 0.8937\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30180\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 88s 778ms/step - loss: 0.0700 - accuracy: 0.9765 - val_loss: 0.2953 - val_accuracy: 0.8961\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.30180 to 0.29535, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 88s 776ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.2935 - val_accuracy: 0.8920\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.29535 to 0.29354, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 85s 753ms/step - loss: 0.0665 - accuracy: 0.9786 - val_loss: 0.2904 - val_accuracy: 0.8953\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.29354 to 0.29040, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 86s 757ms/step - loss: 0.0689 - accuracy: 0.9781 - val_loss: 0.2934 - val_accuracy: 0.8969\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29040\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 84s 747ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.2883 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.29040 to 0.28826, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 84s 747ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.2952 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.28826\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 84s 742ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 0.2864 - val_accuracy: 0.9011\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.28826 to 0.28642, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 85s 754ms/step - loss: 0.0565 - accuracy: 0.9837 - val_loss: 0.2806 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.28642 to 0.28059, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 85s 756ms/step - loss: 0.0684 - accuracy: 0.9761 - val_loss: 0.2794 - val_accuracy: 0.9027\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.28059 to 0.27943, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 85s 749ms/step - loss: 0.0528 - accuracy: 0.9841 - val_loss: 0.2769 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.27943 to 0.27686, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 85s 751ms/step - loss: 0.0551 - accuracy: 0.9814 - val_loss: 0.2799 - val_accuracy: 0.9044\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.27686\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 84s 743ms/step - loss: 0.0573 - accuracy: 0.9831 - val_loss: 0.2670 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.27686 to 0.26697, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 84s 747ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.2849 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.26697\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 85s 748ms/step - loss: 0.0550 - accuracy: 0.9834 - val_loss: 0.2805 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.26697\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 85s 749ms/step - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.2881 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.26697\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 84s 744ms/step - loss: 0.0566 - accuracy: 0.9836 - val_loss: 0.2839 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.26697\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 84s 742ms/step - loss: 0.0531 - accuracy: 0.9839 - val_loss: 0.2761 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.26697\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 84s 743ms/step - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.2809 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.26697\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 84s 740ms/step - loss: 0.0507 - accuracy: 0.9855 - val_loss: 0.2724 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.26697\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 84s 742ms/step - loss: 0.0503 - accuracy: 0.9840 - val_loss: 0.2685 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.26697\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 84s 745ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.2657 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.26697 to 0.26567, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 85s 749ms/step - loss: 0.0554 - accuracy: 0.9809 - val_loss: 0.2670 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.26567\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 84s 746ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.2628 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.26567 to 0.26282, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 85s 750ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.2662 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.26282\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 84s 745ms/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.2697 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26282\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 84s 746ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.2713 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.26282\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 85s 750ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.2727 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.26282\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 85s 754ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.2701 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.26282\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 84s 743ms/step - loss: 0.0394 - accuracy: 0.9886 - val_loss: 0.2638 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26282\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 84s 743ms/step - loss: 0.0430 - accuracy: 0.9881 - val_loss: 0.2663 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26282\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 83s 738ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.2624 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.26282 to 0.26238, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 85s 756ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.2633 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26238\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 85s 755ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.2610 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.26238 to 0.26101, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 84s 746ms/step - loss: 0.0498 - accuracy: 0.9864 - val_loss: 0.2555 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26101 to 0.25549, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 86s 758ms/step - loss: 0.0420 - accuracy: 0.9886 - val_loss: 0.2572 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.25549\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 85s 753ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 0.2614 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.25549\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 85s 748ms/step - loss: 0.0481 - accuracy: 0.9834 - val_loss: 0.2511 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.25549 to 0.25110, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 86s 764ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.2563 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.25110\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 87s 769ms/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.2570 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.25110\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 87s 770ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 0.2531 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.25110\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 87s 774ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.2565 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25110\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 87s 773ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.2591 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.25110\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 86s 763ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 0.2555 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25110\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 87s 766ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.2642 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25110\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 88s 775ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.2566 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25110\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 89s 787ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.2528 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25110\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 89s 785ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.2578 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25110\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 88s 775ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.2482 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.25110 to 0.24815, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 86s 757ms/step - loss: 0.0431 - accuracy: 0.9862 - val_loss: 0.2514 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.24815\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 84s 746ms/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.2502 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.24815\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 84s 745ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.2444 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.24815 to 0.24436, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 84s 746ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.2463 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.24436\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 84s 744ms/step - loss: 0.0337 - accuracy: 0.9903 - val_loss: 0.2487 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.24436\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 84s 740ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.2476 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.24436\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 85s 754ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.2491 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.24436\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 85s 755ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.2441 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.24436 to 0.24407, saving model to checkpoints-finetuning.hdf5\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 86s 758ms/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.2398 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.24407 to 0.23975, saving model to checkpoints-finetuning.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = model.fit_generator(\n",
    "    aug.flow(train_x,train_y, batch_size = 32),\n",
    "             validation_data = (test_x,test_y),\n",
    "             epochs=num_of_epochs,\n",
    "             steps_per_epoch = len(train_x) //32,\n",
    "             verbose = 1,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after initialization...\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         ___Appids     0.8566    0.9876    0.9175       242\n",
      "___Curly_top_virus     1.0000    0.4155    0.5871       142\n",
      "   ___Early_blight     0.9177    0.9870    0.9511       384\n",
      "     ___Leaf_miner     0.9351    0.9708    0.9526       445\n",
      "\n",
      "       avg / total     0.9215    0.9143    0.9023      1213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(test_x,batch_size=batch_size)\n",
    "\n",
    "print(classification_report(test_y.argmax(axis =1),\n",
    "                            predictions.argmax(axis =1),\n",
    "                            target_names=class_names, \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_paths_validation = ['../datasets/validation/___Early_blight', '../datasets/validation/___Appids', '../datasets/validation/___Leaf_miner', '../datasets/self/___Curly_top_virus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO]: Processed 500/614\n",
      "[INFO] evaluating with validation set...\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         ___Appids     0.2727    1.0000    0.4286         9\n",
      "___Curly_top_virus     1.0000    0.4576    0.6279       118\n",
      "   ___Early_blight     0.3871    1.0000    0.5581        12\n",
      "     ___Leaf_miner     0.3611    0.8667    0.5098        15\n",
      "\n",
      "       avg / total     0.8475    0.5714    0.5993       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train_x,test_x,train_y,test_y, class_names) = load_datasets(class_paths_validation)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"[INFO] evaluating with validation set...\")\n",
    "predictions = model.predict(test_x,batch_size=batch_size)\n",
    "\n",
    "print(classification_report(test_y.argmax(axis =1),\n",
    "                            predictions.argmax(axis =1),\n",
    "                            target_names=class_names, \n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
